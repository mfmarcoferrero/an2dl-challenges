{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsXsEar9SLjU"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omSLbdLvhDRx"
      },
      "source": [
        "### Connect to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoaLQpvChLpb",
        "outputId": "c2822d61-03f3-47c9-e177-a49b5618ae8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 3] Impossibile trovare il percorso specificato: '../AN2DL_Challenges/Challenge_1/'\n",
            "c:\\Users\\danie\\Desktop\\classifier\\AN2DL_Challenges\\Challenge_1\n"
          ]
        }
      ],
      "source": [
        "cd ../AN2DL_Challenges/Challenge_1/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnvxMr6lmGcf"
      },
      "source": [
        "#Loading dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldds6UPGqrK9",
        "outputId": "1621f308-9da6-470e-b9bb-a7d9e8d6121c"
      },
      "outputs": [],
      "source": [
        "#!pip install opencv-python==4.6.0.66\n",
        "#!pip install pyyaml==6.0\n",
        "#!pip install scikit-image==0.18.3\n",
        "#!pip install scikit-learn==1.0.2\n",
        "#!pip install Cython==0.29.32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ktsJkNLL9Fq",
        "outputId": "01baf792-5386-4fde-c855-8eb69d3ea147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.10.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import h5py\n",
        "import psutil\n",
        "import tqdm\n",
        "import imutils\n",
        "import scipy\n",
        "import cv2\n",
        "import yaml\n",
        "import skimage\n",
        "import sklearn\n",
        "import Cython\n",
        "import seaborn \n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdD_8Vyswkwf"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPFu3AYbLCWg"
      },
      "source": [
        "\n",
        "Libraries installed in the evaluation machine:\n",
        "\n",
        "    tensorflow==2.10.0 x\n",
        "    Cython==0.29.32 \n",
        "    numpy==1.21.6 x\n",
        "    matplotlib==3.2.2\n",
        "    seaborn==0.11.2\n",
        "    scipy==1.7.3\n",
        "    scikit-learn==1.0.2\n",
        "    scikit-image==0.18.3\n",
        "    pandas==1.3.5 x\n",
        "    pyyaml==6.0\n",
        "    imutils==0.5.4\n",
        "    opencv-python==4.6.0.66\n",
        "    tqdm==4.64.1\n",
        "    psutil==5.4.8\n",
        "    h5py==3.1.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHwWVPpSi0Np",
        "outputId": "16e4b040-2cb7-4810-d8fd-36d5191b8288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: visualkeras in c:\\users\\danie\\miniconda3\\envs\\tf\\lib\\site-packages (0.0.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\danie\\miniconda3\\envs\\tf\\lib\\site-packages (from visualkeras) (9.3.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\danie\\miniconda3\\envs\\tf\\lib\\site-packages (from visualkeras) (1.23.4)\n",
            "Requirement already satisfied: aggdraw>=1.3.11 in c:\\users\\danie\\miniconda3\\envs\\tf\\lib\\site-packages (from visualkeras) (1.3.15)\n"
          ]
        }
      ],
      "source": [
        "# Install and import visualkeras library\n",
        "# ---> CAN'T BE USED IN THE FINAL SUBMIT\n",
        "#!pip install visualkeras\n",
        "import visualkeras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLb-N5JzUUQS"
      },
      "source": [
        "### Set seed for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "C7HYua8HUHIj"
      },
      "outputs": [],
      "source": [
        "# Random seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDM82PpE3VSg"
      },
      "source": [
        "### Suppress warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5fXtacjAqOIq"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import logging\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "tf.get_logger().setLevel('INFO')\n",
        "tf.autograph.set_verbosity(0)\n",
        "\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvjjNtBV_jBQ"
      },
      "source": [
        "## Plants dataset\n",
        "\n",
        "Pictures of different kinds of plants.\n",
        "\n",
        "Class labels:\n",
        "1. \"Species1\"\n",
        "2. \"Species2\"\n",
        "3. \"Species3\"\n",
        "4. \"Species4\"\n",
        "5. \"Species5\"\n",
        "6. \"Species6\"\n",
        "7. \"Species7\"\n",
        "8. \"Species8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRL3G8yL8BPL",
        "outputId": "3147314d-3c1c-40af-977f-dcf076c84062"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\"unzip\" non ï¿½ riconosciuto come comando interno o esterno,\n",
            " un programma eseguibile o un file batch.\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset to be used for classification\n",
        "!unzip MY_training_dataset_homework1.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSmn5M8_PyJ1",
        "outputId": "7b89cafe-4da8-4fd8-c212-581ec10dfe10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ],
      "source": [
        "#!pip install split-folders\n",
        "import splitfolders\n",
        "# Dataset folder\n",
        "dataset_dir = 'training_data_final'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmdk3qtF89ED",
        "outputId": "3d24d0c7-d84f-45fd-ddf1-d44c68978403"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying files: 3542 files [00:38, 91.66 files/s] \n"
          ]
        }
      ],
      "source": [
        "#splitfolders.ratio(dataset_dir, output=\"splitted_dataset\", seed=seed, ratio=(.8,.1,.1), group_prefix=None, move=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "x1eHR78F_Bbc"
      },
      "outputs": [],
      "source": [
        "dataset_dir = 'splitted_dataset'\n",
        "training_dir = os.path.join(dataset_dir, 'train')\n",
        "validation_dir = os.path.join(dataset_dir, 'val')\n",
        "test_dir = os.path.join(dataset_dir, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3_NfMXE9Ka6",
        "outputId": "eeee6a1d-8bb8-4e98-d0d6-ebde3e7456df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2829 images belonging to 8 classes.\n",
            "Found 351 images belonging to 8 classes.\n",
            "Found 362 images belonging to 8 classes.\n"
          ]
        }
      ],
      "source": [
        "# Images are divided into folders, one for each class. \n",
        "# If the images are organized in such a way, we can exploit the \n",
        "# ImageDataGenerator to read them from disk.\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create an instance of ImageDataGenerator for training, validation, and test sets\n",
        "train_data_gen = ImageDataGenerator()\n",
        "valid_data_gen = ImageDataGenerator()\n",
        "test_data_gen = ImageDataGenerator()\n",
        "\n",
        "# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\n",
        "train_gen = train_data_gen.flow_from_directory(directory=training_dir,\n",
        "                                               target_size=(96,96),\n",
        "                                               color_mode='rgb',\n",
        "                                               classes=None, # can be set to labels\n",
        "                                               class_mode='categorical',\n",
        "                                               batch_size=8,\n",
        "                                               shuffle=True,\n",
        "                                               seed=seed)\n",
        "valid_gen = train_data_gen.flow_from_directory(directory=validation_dir,\n",
        "                                               target_size=(96,96),\n",
        "                                               color_mode='rgb',\n",
        "                                               classes=None, # can be set to labels\n",
        "                                               class_mode='categorical',\n",
        "                                               batch_size=8,\n",
        "                                               shuffle=False,\n",
        "                                               seed=seed)\n",
        "test_gen = train_data_gen.flow_from_directory(directory=test_dir,\n",
        "                                              target_size=(96,96),\n",
        "                                              color_mode='rgb',\n",
        "                                              classes=None, # can be set to labels\n",
        "                                              class_mode='categorical',\n",
        "                                              batch_size=8,\n",
        "                                              shuffle=False,\n",
        "                                              seed=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbONXqDp_WhR",
        "outputId": "e29f24fe-ad30-4c77-efed-064aa262c57a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assigned labels\n",
            "{'Species1': 0, 'Species2': 1, 'Species3': 2, 'Species4': 3, 'Species5': 4, 'Species6': 5, 'Species7': 6, 'Species8': 7}\n",
            "\n",
            "Target classes\n",
            "[0 0 0 ... 7 7 7]\n"
          ]
        }
      ],
      "source": [
        "print(\"Assigned labels\")\n",
        "print(train_gen.class_indices)\n",
        "print()\n",
        "print(\"Target classes\")\n",
        "print(train_gen.classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoNn1tc0BstG"
      },
      "source": [
        "Set is divided into batches:\n",
        "# What is a batch ?\n",
        "The batch size is a hyperparameter that defines the number of samples to work through before updating the internal model parameters.\n",
        "\n",
        "Think of a batch as a for-loop iterating over one or more samples and making predictions. At the end of the batch, the predictions are compared to the expected output variables and an error is calculated. From this error, the update algorithm is used to improve the model, e.g. move down along the error gradient.\n",
        "\n",
        "A training dataset can be divided into one or more batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5D5ln0cHVL2b"
      },
      "outputs": [],
      "source": [
        "def get_next_batch(generator):\n",
        "  batch = next(generator)\n",
        "\n",
        "  image = batch[0]\n",
        "  target = batch[1]\n",
        "\n",
        "  print(\"(Input) image shape:\", image.shape)\n",
        "  print(\"Target shape:\",target.shape)\n",
        "\n",
        "  # Visualize only the first sample\n",
        "  image = image[0]\n",
        "  target = target[0]\n",
        "  target_idx = np.argmax(target)\n",
        "  print()\n",
        "  print(\"Categorical label:\", target)\n",
        "  print(\"Label:\", target_idx)\n",
        "  print(\"Class name:\", labels[target_idx])\n",
        "  fig = plt.figure(figsize=(6, 4))\n",
        "  plt.imshow(np.uint8(image))\n",
        "\n",
        "  return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "WJ6q1cJLalh7",
        "outputId": "48dc1399-9909-44b8-874f-22cfda2a2901"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(Input) image shape: (8, 96, 96, 3)\n",
            "Target shape: (8, 8)\n",
            "\n",
            "Categorical label: [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "Label: 3\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'labels' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Get a sample from dataset and show info\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m _ \u001b[39m=\u001b[39m get_next_batch(train_gen)\n",
            "Cell \u001b[1;32mIn [15], line 17\u001b[0m, in \u001b[0;36mget_next_batch\u001b[1;34m(generator)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCategorical label:\u001b[39m\u001b[39m\"\u001b[39m, target)\n\u001b[0;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLabel:\u001b[39m\u001b[39m\"\u001b[39m, target_idx)\n\u001b[1;32m---> 17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mClass name:\u001b[39m\u001b[39m\"\u001b[39m, labels[target_idx])\n\u001b[0;32m     18\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m6\u001b[39m, \u001b[39m4\u001b[39m))\n\u001b[0;32m     19\u001b[0m plt\u001b[39m.\u001b[39mimshow(np\u001b[39m.\u001b[39muint8(image))\n",
            "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
          ]
        }
      ],
      "source": [
        "# Get a sample from dataset and show info\n",
        "_ = get_next_batch(train_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7eBGvBAocGL"
      },
      "source": [
        "# Training WITHOUT data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUA94y1ZoVFc",
        "outputId": "0388dbe9-9e7f-4ba8-a69a-0b7c16d4fb28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2829 images belonging to 8 classes.\n",
            "Found 351 images belonging to 8 classes.\n",
            "Found 362 images belonging to 8 classes.\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of ImageDataGenerator with NO Data Augmentation\n",
        "train_data_gen = ImageDataGenerator(rescale=1/96.) # rescale value is multiplied to the image\n",
        "valid_data_gen = ImageDataGenerator(rescale=1/96.)\n",
        "test_data_gen = ImageDataGenerator(rescale=1/96.)\n",
        "\n",
        "# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\n",
        "train_gen = train_data_gen.flow_from_directory(directory=training_dir,\n",
        "                                                           target_size=(96,96),\n",
        "                                                           color_mode='rgb',\n",
        "                                                           classes=None, # can be set to labels\n",
        "                                                           class_mode='categorical',\n",
        "                                                           batch_size=8,\n",
        "                                                           shuffle=True,\n",
        "                                                           seed=seed)\n",
        "valid_gen = valid_data_gen.flow_from_directory(directory=validation_dir,\n",
        "                                               target_size=(96,96),\n",
        "                                               color_mode='rgb',\n",
        "                                               classes=None, # can be set to labels\n",
        "                                               class_mode='categorical',\n",
        "                                               batch_size=8,\n",
        "                                               shuffle=False,\n",
        "                                               seed=seed)\n",
        "test_gen = test_data_gen.flow_from_directory(directory=test_dir,\n",
        "                                             target_size=(96,96),\n",
        "                                             color_mode='rgb',\n",
        "                                             classes=None, # can be set to labels\n",
        "                                             class_mode='categorical',\n",
        "                                             batch_size=8,\n",
        "                                             shuffle=False,\n",
        "                                             seed=seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr9CX7CYdBg_"
      },
      "source": [
        "### Models metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YcxBMJhl4EM"
      },
      "outputs": [],
      "source": [
        "input_shape = (96, 96, 3)\n",
        "epochs = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXmw4F0wlY0h"
      },
      "source": [
        "### CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkccDbv-bzKr"
      },
      "outputs": [],
      "source": [
        "def build_model(input_shape):\n",
        "\n",
        "    # Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=3,\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(input_layer)\n",
        "    pool1 = tfkl.MaxPooling2D()(conv1)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=3,\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(pool1)\n",
        "    pool2 = tfkl.MaxPooling2D()(conv2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=3,\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D()(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=256,\n",
        "        kernel_size=3,\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(pool3)\n",
        "    pool4 = tfkl.MaxPooling2D()(conv4)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=512,\n",
        "        kernel_size=3,\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D()(conv5)\n",
        "\n",
        "    flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    dropout = tfkl.Dropout(0.3, seed=seed)(flattening_layer)\n",
        "    classifier_layer = tfkl.Dense(units=512, name='Classifier', kernel_initializer=tfk.initializers.HeUniform(seed), activation='relu')(dropout)\n",
        "    dropout = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n",
        "    output_layer = tfkl.Dense(units=8, activation='softmax', kernel_initializer=tfk.initializers.GlorotUniform(seed), name='output_layer')(dropout)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnGGNXWY9zNF",
        "outputId": "2802363c-02b6-4208-d303-99f84e8f0e90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: visualkeras in /usr/local/lib/python3.7/dist-packages (0.0.2)\n",
            "Requirement already satisfied: aggdraw>=1.3.11 in /usr/local/lib/python3.7/dist-packages (from visualkeras) (1.3.15)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from visualkeras) (1.21.6)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from visualkeras) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "# Download and import visualkeras library\n",
        "!pip install visualkeras\n",
        "import visualkeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NwsjIp_crOKq",
        "outputId": "239c9351-ee61-4ddc-bb7d-c9e33d45e981"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 96, 96, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 96, 96, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 48, 48, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 48, 48, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 24, 24, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 12, 12, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 6, 6, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 6, 6, 512)         1180160   \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 3, 3, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " Flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 4608)              0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 512)               2359808   \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 8)                 4104      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,932,488\n",
            "Trainable params: 3,932,488\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<PIL.Image.Image image mode=RGBA size=1438x420 at 0x7F7F398F6310>"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Build model (for NO augmentation training)\n",
        "model = build_model(input_shape)\n",
        "model.summary()\n",
        "visualkeras.layered_view(model, legend=True, spacing=10, scale_xy=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9nLz1TKGcCu"
      },
      "outputs": [],
      "source": [
        "# Utility function to create folders and callbacks for training\n",
        "from datetime import datetime\n",
        "\n",
        "def create_folders_and_callbacks(model_name):\n",
        "\n",
        "  exps_dir = os.path.join('data_augmentation_experiments')\n",
        "  if not os.path.exists(exps_dir):\n",
        "      os.makedirs(exps_dir)\n",
        "\n",
        "  now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "\n",
        "  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
        "  if not os.path.exists(exp_dir):\n",
        "      os.makedirs(exp_dir)\n",
        "      \n",
        "  callbacks = []\n",
        "\n",
        "  # Model checkpoint\n",
        "  # ----------------\n",
        "  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
        "  if not os.path.exists(ckpt_dir):\n",
        "      os.makedirs(ckpt_dir)\n",
        "\n",
        "  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), \n",
        "                                                     save_weights_only=True, # True to save only weights\n",
        "                                                     save_best_only=False) # True to save only the best epoch \n",
        "  callbacks.append(ckpt_callback)\n",
        "\n",
        "  # Visualize Learning on Tensorboard\n",
        "  # ---------------------------------\n",
        "  tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
        "  if not os.path.exists(tb_dir):\n",
        "      os.makedirs(tb_dir)\n",
        "      \n",
        "  # By default shows losses and metrics for both training and validation\n",
        "  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir, \n",
        "                                               profile_batch=0,\n",
        "                                               histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n",
        "  callbacks.append(tb_callback)\n",
        "\n",
        "  # Early Stopping\n",
        "  # --------------\n",
        "  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
        "  callbacks.append(es_callback)\n",
        "\n",
        "  return callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hln5Up0XtOs9",
        "outputId": "68b759c3-739d-4f19-e366-451316288806"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "354/354 [==============================] - 124s 348ms/step - loss: 2.1642 - accuracy: 0.2768 - val_loss: 1.8138 - val_accuracy: 0.3390\n",
            "Epoch 2/3\n",
            "354/354 [==============================] - 123s 347ms/step - loss: 1.5696 - accuracy: 0.4146 - val_loss: 1.4117 - val_accuracy: 0.4672\n",
            "Epoch 3/3\n",
            "354/354 [==============================] - 124s 350ms/step - loss: 1.4617 - accuracy: 0.4532 - val_loss: 1.5899 - val_accuracy: 0.3618\n"
          ]
        }
      ],
      "source": [
        "# Create folders and callbacks and fit\n",
        "noaug_callbacks = create_folders_and_callbacks(model_name='CNN_NoAug')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x = train_gen,\n",
        "    epochs = epochs,\n",
        "    validation_data = valid_gen,\n",
        "    callbacks = noaug_callbacks,\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6m-yQ1bug3o",
        "outputId": "54df804e-e95f-4d9d-a181-24d8f8bca53b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "# Save best epoch model\n",
        "model.save(\"data_augmentation_experiments/CNN_NoAug_Best\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86GXG1T-02-t",
        "outputId": "f4aacd34-f4bd-459a-8ccd-dc849848c46c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46/46 [==============================] - 5s 98ms/step - loss: 1.6226 - accuracy: 0.3923\n",
            "\n",
            "Test metrics without data augmentation\n",
            "{'loss': 1.6226375102996826, 'accuracy': 0.3922652006149292}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on test\n",
        "# Trainined with no data augmentation\n",
        "model_noaug = tfk.models.load_model(\"data_augmentation_experiments/CNN_NoAug_Best\")\n",
        "model_noaug_test_metrics = model_noaug.evaluate(test_gen, return_dict=True)\n",
        "# Trained with data augmentation\n",
        "# model_aug = tfk.models.load_model(\"data_augmentation_experiments/CNN_Aug_Best\")\n",
        "# model_aug_test_metrics = model_aug.evaluate(test_gen, return_dict=True)\n",
        "\n",
        "print()\n",
        "print(\"Test metrics without data augmentation\")\n",
        "print(model_noaug_test_metrics)\n",
        "# print(\"Test metrics with data augmentation\")\n",
        "# print(model_aug_test_metrics)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "b92c64ddd97bd75b75879c676e53789d19cf25aafb287fcc8a3273f02b13a1d2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

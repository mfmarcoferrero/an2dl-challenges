{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsXsEar9SLjU"
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnvxMr6lmGcf"
   },
   "source": [
    "### Loading dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1668176641220,
     "user": {
      "displayName": "Marco Ferrero",
      "userId": "12365802642267231519"
     },
     "user_tz": -60
    },
    "id": "8ktsJkNLL9Fq",
    "outputId": "e52a83f9-6492-4d11-a850-8af0c984f19f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "\n",
    "import visualkeras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLb-N5JzUUQS"
   },
   "source": [
    "### Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7HYua8HUHIj"
   },
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDM82PpE3VSg"
   },
   "source": [
    "### Suppress warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5fXtacjAqOIq"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "tf.get_logger().setLevel('INFO')\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvjjNtBV_jBQ"
   },
   "source": [
    "## Plants dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "x1eHR78F_Bbc"
   },
   "outputs": [],
   "source": [
    "dataset_dir = './datasetTEST'\n",
    "training_dir = os.path.join(dataset_dir, 'train')\n",
    "validation_dir = os.path.join(dataset_dir, 'val')\n",
    "test_dir = os.path.join(dataset_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-UrdOzQ2-Jqe"
   },
   "outputs": [],
   "source": [
    "# Plot example images from dataset\n",
    "labels = [\n",
    "          'Species1',   # 0\n",
    "          'Species2',   # 1\n",
    "          'Species3',   # 2\n",
    "          'Species4',   # 3\n",
    "          'Species5',   # 4\n",
    "          'Species6',   # 5\n",
    "          'Species7',   # 6\n",
    "          'Species8',   # 7\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jr9CX7CYdBg_"
   },
   "source": [
    "### Models metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Parameters\n",
    "img_w = 96\n",
    "img_h = 96\n",
    "input_shape = (96, 96, 3)\n",
    "classes = 8\n",
    "\n",
    "# Training Parameters\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "learning_rate_high = 1e-2\n",
    "learning_rate_low = 1e-5\n",
    "\n",
    "# Earlystopping Parameters\n",
    "early_stopping = True\n",
    "patience_epochs = 10\n",
    "\n",
    "# Data Augmentation\n",
    "apply_augmentation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(train_gen.classes), \n",
    "            y=train_gen.classes)\n",
    "# Keras requires a dictionary\n",
    "class_weights = {i : class_weights[i] for i in range(len(class_weights))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "\n",
    "def adjust_brightness(im, factor):\n",
    "    im = tf.keras.utils.array_to_img(im)\n",
    "    #image brightness enhancer\n",
    "    enhancer = ImageEnhance.Brightness(im)\n",
    "    \n",
    "    im_output = enhancer.enhance(factor)\n",
    "    im_output = tf.keras.utils.img_to_array(im_output)\n",
    "    return im_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image_gen):\n",
    "    image_saturated = tf.image.adjust_saturation(image_gen,2.5)\n",
    "    image_brightness = adjust_brightness(image_saturated, 1.2)\n",
    "    \n",
    "    return image_brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "WJ6q1cJLalh7"
   },
   "outputs": [],
   "source": [
    "valid_data_gen = ImageDataGenerator(rescale = 1./255, preprocessing_function = preprocessing)\n",
    "test_data_gen = ImageDataGenerator(rescale = 1./255, preprocessing_function = preprocessing)\n",
    "\n",
    "valid_gen = valid_data_gen.flow_from_directory(directory=validation_dir,\n",
    "                                               target_size=(img_w,img_h),\n",
    "                                               color_mode='rgb',\n",
    "                                               classes=None, # can be set to labels\n",
    "                                               class_mode='categorical',\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               seed=seed)\n",
    "test_gen = test_data_gen.flow_from_directory(directory=test_dir,\n",
    "                                             target_size=(img_w,img_h),\n",
    "                                             color_mode='rgb',\n",
    "                                             classes=None, # can be set to labels\n",
    "                                             class_mode='categorical',\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of ImageDataGenerator with Data Augmentation\n",
    "if apply_augmentation:\n",
    "    train_data_gen = ImageDataGenerator(rotation_range=10,\n",
    "                                        width_shift_range=5,\n",
    "                                        height_shift_range=5,\n",
    "                                        zoom_range=0.2,\n",
    "                                        horizontal_flip=True,\n",
    "                                        vertical_flip=True,\n",
    "                                        #brightness_range=[0.5, 1.4],\n",
    "                                        fill_mode='reflect',\n",
    "                                        rescale= 1./255)  # rescale value is multiplied to the image\n",
    "    print(\"AUGMENTED DATASET\")\n",
    "else:\n",
    "    train_data_gen = ImageDataGenerator(rescale = 1./255, preprocessing_function = preprocessing)\n",
    "    print(\"NON-AUGMENTED DATASET\")\n",
    "\n",
    "# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\n",
    "train_gen = train_data_gen.flow_from_directory(directory=training_dir,\n",
    "                                                target_size=(img_w,img_h),\n",
    "                                                color_mode='rgb',\n",
    "                                                classes=None, # can be set to labels\n",
    "                                                class_mode='categorical',\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=True,\n",
    "                                                seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXmw4F0wlY0h"
   },
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_basic_model(input_shape):\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    # Build the neural network layer by layer\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
    "    \n",
    "    x = tfkl.Conv2D(\n",
    "        filters = 25,\n",
    "        kernel_size = 3,\n",
    "        padding = 'same',\n",
    "        kernel_initializer = tfk.initializers.HeUniform(seed),\n",
    "        name = 'conv1')(input_layer)\n",
    "    x = tfkl.ReLU()(x)\n",
    "    x = tfkl.MaxPooling2D(name='mp1')(x)\n",
    "\n",
    "    x = tfkl.Conv2D(\n",
    "        filters = 50,\n",
    "        kernel_size = 3,\n",
    "        padding = 'same',\n",
    "        kernel_initializer = tfk.initializers.HeUniform(seed),\n",
    "        name = 'conv2')(x)\n",
    "    x = tfkl.ReLU()(x)\n",
    "    x = tfkl.MaxPooling2D(name='mp2')(x)\n",
    "\n",
    "    x = tfkl.Conv2D(\n",
    "        filters = 100,\n",
    "        kernel_size = 3,\n",
    "        padding = 'same',\n",
    "        kernel_initializer = tfk.initializers.HeUniform(seed),\n",
    "        name = 'conv3')(x)\n",
    "    x = tfkl.ReLU()(x)\n",
    "    x = tfkl.MaxPooling2D(name='mp3')(x)\n",
    "\n",
    "    x = tfkl.GlobalAveragePooling2D(name='GAP_Layer')(x)\n",
    "    x = Dropout(0.3, seed=seed, name='classifier_dropout_1')(x)\n",
    "    x = tfkl.Dense(\n",
    "        units = 256,\n",
    "        kernel_initializer = tfk.initializers.HeUniform(seed),\n",
    "        name = 'classifier')(x)\n",
    "    x = tfkl.ReLU()(x)\n",
    "    x = tfkl.Dropout(0.3, seed=seed, name='classifier_dropout_2')(x)\n",
    "\n",
    "    output_layer = tfkl.Dense(\n",
    "        units = classes, \n",
    "        activation = 'softmax', \n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
    "        name = 'output_layer')(x)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs = input_layer, outputs = output_layer, name = 'BasicModel')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model = build_basic_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate Scheduler\n",
    "def scheduler(epoch, lr):\n",
    "   if epoch < 100:\n",
    "     return lr\n",
    "   else:\n",
    "     return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create folders and callbacks for training\n",
    "def create_folders_and_callbacks(model_name) :\n",
    "    callbacks = []\n",
    "\n",
    "    # Early Stopping -----------------------------------------------------\n",
    "    if early_stopping:\n",
    "        es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', patience=patience_epochs, restore_best_weights=True)\n",
    "        callbacks.append(es_callback)\n",
    "\n",
    "    # Checkpointer\n",
    "    checkpointer = tfk.callbacks.ModelCheckpoint(filepath='./checkpoint/weights_basic_model.h5', verbose=1, \n",
    "                                    save_best_only=True, monitor = \"val_accuracy\", mode = \"auto\",)\n",
    "    callbacks.append(checkpointer)\n",
    "    \n",
    "    # Learning Rate Scheduler --------------------------------------------\n",
    "    LRS_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "    callbacks.append(LRS_callback)\n",
    "    \n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = create_folders_and_callbacks(model_name='CustomCNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "basic_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
    "\n",
    "basic_history = basic_model.fit(\n",
    "    x = train_gen,\n",
    "    class_weight = class_weights,\n",
    "    epochs = epochs,\n",
    "    validation_data = valid_gen,\n",
    "    callbacks = callbacks,\n",
    ").history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data_gen = ImageDataGenerator(rescale = 1./255, preprocessing_function = preprocessing)\n",
    "test_data_gen = ImageDataGenerator(rescale = 1./255, preprocessing_function = preprocessing)\n",
    "\n",
    "valid_gen = valid_data_gen.flow_from_directory(directory=validation_dir,\n",
    "                                               target_size=(img_w,img_h),\n",
    "                                               color_mode='rgb',\n",
    "                                               classes=None, # can be set to labels\n",
    "                                               class_mode='categorical',\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=False,\n",
    "                                               seed=seed)\n",
    "test_gen = test_data_gen.flow_from_directory(directory=test_dir,\n",
    "                                             target_size=(img_w,img_h),\n",
    "                                             color_mode='rgb',\n",
    "                                             classes=None, # can be set to labels\n",
    "                                             class_mode='categorical',\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=False,\n",
    "                                             seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix on test set\n",
    "test_steps_per_epoch = np.math.ceil(test_gen.samples / test_gen.batch_size)\n",
    "\n",
    "# Evaluate on test\n",
    "predictions = basic_model.predict(test_gen, steps=test_steps_per_epoch)\n",
    "\n",
    "# Get most likely classes\n",
    "predicted_classes = np.argmax(predictions, axis=-1)\n",
    "\n",
    "# Get true classes\n",
    "true_classes = test_gen.classes\n",
    "class_labels = list(test_gen.class_indices.keys())\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "# Compute the classification metrics\n",
    "accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "precision = precision_score(true_classes, predicted_classes, average='macro')\n",
    "recall = recall_score(true_classes, predicted_classes, average='macro')\n",
    "f1 = f1_score(true_classes, predicted_classes, average='macro')\n",
    "print('Accuracy:',accuracy.round(4))\n",
    "print('Precision:',precision.round(4))\n",
    "print('Recall:',recall.round(4))\n",
    "print('F1:',f1.round(4))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.heatmap(cm.T, xticklabels=list(class_labels), yticklabels=class_labels)\n",
    "plt.xlabel('True labels')\n",
    "plt.ylabel('Predicted labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Confusion Matrix and Classification Report (Precision, Recall, and F1-score) on the validation set\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "Y_prediction = basic_model.predict_generator(valid_gen, len(valid_gen))\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_prediction,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = valid_gen.classes\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
    "class_report = classification_report(Y_true, Y_pred_classes, \n",
    "                                     target_names=valid_gen.class_indices.keys())  # target_names must be ordered depending on the class labels\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_mtx)\n",
    "print()\n",
    "print('Classification Report:')\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict basic_model\n",
    "print(\"Basic model: \")\n",
    "model_test_metrics = basic_model.evaluate(test_gen, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.plot(basic_history['loss'], alpha=.3, color='#4D61E2', linestyle='--')\n",
    "plt.plot(basic_history['val_loss'], label='Basic model', alpha=.8, color='#4D61E2')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Categorical Crossentropy')\n",
    "plt.grid(alpha=.3)\n",
    "\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(basic_history['accuracy'], alpha=.3, color='#77bbff', linestyle='--')\n",
    "plt.plot(basic_history['val_accuracy'], label='Basic model', alpha=.8, color='#77bbff')\n",
    "\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Accuracy')\n",
    "plt.grid(alpha=.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model.save('basic_model_saturation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3290ac40e0d8af326e9fa8b5af1332b8130b7bdc681180ec5173f972b61b017"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

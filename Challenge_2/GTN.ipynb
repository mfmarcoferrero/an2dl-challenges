{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZsfzLu3em92",
        "outputId": "c520c0ca-0ba5-4e22-f80b-18575ce7b028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', size=16) \n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import warnings\n",
        "import logging\n",
        "import math\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)"
      ],
      "metadata": {
        "id": "cX3GhZuQevTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%cd /content/drive/MyDrive/2022_AN2DL(Private)\n",
        "!yes | unzip training_dataset_homework2.zip\n",
        "\n",
        "data = np.load('x_train.npy')\n",
        "labels = np.load('y_train.npy')\n",
        "\n",
        "from sklearn.utils import compute_class_weight\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(labels),\n",
        "                                        y = labels                                                    \n",
        "                                    )\n",
        "class_weights = dict(zip(np.unique(labels), class_weights))\n",
        "class_weights\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(data, labels, test_size=0.2, shuffle= True)\n",
        "\n",
        "y_train = tfk.utils.to_categorical(y_train)\n",
        "y_valid = tfk.utils.to_categorical(y_valid)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "classes = y_train.shape[-1]\n",
        "batch_size = 3\n",
        "epochs = 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MVfFQ3vex1O",
        "outputId": "55c64f00-9264-40ef-e389-8b0feb47a756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/2022_AN2DL(Private)\n",
            "Archive:  training_dataset_homework2.zip\n",
            "replace y_train.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: y_train.npy             \n",
            "replace x_train.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: x_train.npy             \n",
            "(1943, 36, 6)\n",
            "(1943, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "AfhFUl5VffaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model parameters\n",
        "\n",
        "d_model = 512 # dense vector dimension\n",
        "d_hidden = 1024 # dimension of hidden layer\n",
        "d_input = 36 # dimension of window \n",
        "d_channel = 6 # number of channels/variables\n",
        "d_output = 12 # number of classes\n",
        "q = 8 #linear mapping dimension in mha\n",
        "v = 8 #linear mapping dimension in mha\n",
        "h = 8 # Number of heads in multihead attention\n",
        "N = 8\n",
        "dropout = 0.2\n",
        "pe = True  \n",
        "mask = True "
      ],
      "metadata": {
        "id": "GiqoGtywQDje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow._api.v2.compat.v1 import float32\n",
        "class MulHeadAtt(tfkl.Layer):\n",
        "    def __init__(self,\n",
        "                 d_model: int,\n",
        "                 q: int,\n",
        "                 v: int,\n",
        "                 h: int,\n",
        "                 mask: bool=False,\n",
        "                 dropout: float = 0.1):\n",
        "        super(MulHeadAtt, self).__init__()\n",
        "\n",
        "        #self.W_q = torch.nn.Linear(d_model, q * h)\n",
        "        #self.W_q = tfkl.Dense((q * h),\n",
        "        #                      input_shape = (d_model,),\n",
        "        #                      activation = None)\n",
        "        self.W_q = self.add_weight(name='W_q', \n",
        "                                   shape=(d_model, q * h),\n",
        "                                   initializer='glorot_uniform')\n",
        "        #self.W_k = torch.nn.Linear(d_model, q * h)\n",
        "        #self.W_k = tfkl.Dense((q * h),\n",
        "        #                      input_shape = (d_model,),\n",
        "        #                      activation = None)\n",
        "        self.W_k = self.add_weight(name='W_k', \n",
        "                                   shape=(d_model, q * h),\n",
        "                                   initializer='glorot_uniform')\n",
        "        #self.W_v = torch.nn.Linear(d_model, v * h)\n",
        "        #self.W_v = tfkl.Dense((v * h),\n",
        "        #                      input_shape = (d_model,),\n",
        "        #                      activation = None)\n",
        "        self.W_v = self.add_weight(name='W_v', \n",
        "                                   shape=(d_model, v * h),\n",
        "                                   initializer='glorot_uniform')\n",
        "\n",
        "        #self.W_o = torch.nn.Linear(v * h, d_model)\n",
        "        #self.W_o = tfkl.Dense(d_model,\n",
        "        #                      input_shape = ((v * h),),\n",
        "        #                      activation = None)\n",
        "        self.W_o = self.add_weight(name='W_o', \n",
        "                                   shape=(v * h, d_model),\n",
        "                                   initializer='glorot_uniform')\n",
        "\n",
        "\n",
        "        #self.device = device\n",
        "        self._h = h\n",
        "        self._q = q\n",
        "\n",
        "        self.mask = mask\n",
        "        #self.dropout = torch.nn.Dropout(p=dropout)\n",
        "        self.dropout = tfkl.Dropout(dropout)\n",
        "        self.score = None\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        # Apply the W_q operation to x and split the result into self._h chunks along the last dimension\n",
        "        q_chunks = tf.split(self.W_q(x), num_or_size_splits=self._h, axis=-1)\n",
        "\n",
        "        # Concatenate the chunks along the first dimension\n",
        "        Q = tf.concat(q_chunks, axis=0)\n",
        "\n",
        "        # Apply the W_k operation to x and split the result into self._h chunks along the last dimension\n",
        "        k_chunks = tf.split(self.W_k(x), num_or_size_splits=self._h, axis=-1)\n",
        "\n",
        "        # Concatenate the chunks along the first dimension\n",
        "        K = tf.concat(k_chunks, axis=0)\n",
        "\n",
        "        # Apply the W_v operation to x and split the result into self._h chunks along the last dimension\n",
        "        v_chunks = tf.split(self.W_v(x), num_or_size_splits=self._h, axis=-1)\n",
        "\n",
        "        # Concatenate the chunks along the first dimension\n",
        "        V = tf.concat(v_chunks, axis=0)\n",
        "\n",
        "        #score = torch.matmul(Q, K.transpose(-1, -2)) / math.sqrt(self._q)\n",
        "        score = tf.linalg.matmul(Q, K, transpose_b = True) / math.sqrt(self._q)\n",
        "        self.score = score\n",
        "\n",
        "        # OMITTING STAGE IMPLEMENTATION!\n",
        "        if self.mask:\n",
        "            # Create a tensor of ones with the same shape as score[0]\n",
        "            mask = tf.ones_like(score[0])\n",
        "\n",
        "            # Create a lower triangular matrix with ones on the main diagonal and zeros elsewhere\n",
        "            mask = tf.linalg.band_part(mask, num_lower=-1, num_upper=0)\n",
        "\n",
        "            # Create a tensor of -2**32+1 with the same shape as score[0]\n",
        "            fill_value = tf.constant(-2**32+1, shape=score[0].shape, dtype=score[0].dtype)\n",
        "\n",
        "            # Expand the fill_value tensor to the same shape as score\n",
        "            shape = tf.shape(score)\n",
        "            fill_value = tf.broadcast_to(fill_value, shape)\n",
        "\n",
        "            # Replace the elements of score where mask is greater than 0 with fill_value\n",
        "            score = tf.where(mask > 0, score, fill_value)\n",
        "        \n",
        "        score = tf.nn.softmax(score, axis=-1)\n",
        "\n",
        "        attention = tf.linalg.matmul(score, V)\n",
        "\n",
        "        # Split attention into self._h chunks along the first dimension\n",
        "        attention_chunks = tf.split(attention, num_or_size_splits=self._h, axis=0)\n",
        "\n",
        "        # Concatenate the chunks along the last dimension\n",
        "        attention_heads = tf.concat(attention_chunks, axis=-1)\n",
        "\n",
        "        self_attention = self.W_o(attention_heads)\n",
        "      \n",
        "        return self_attention, self.score\n",
        "\n",
        "class FeedFwd(tfkl.Layer):\n",
        "    def __init__(self,\n",
        "                 d_model: int,\n",
        "                 d_hidden: int = 512):\n",
        "        super(FeedFwd, self).__init__()\n",
        "\n",
        "        self.linear_1 = tfkl.Dense(d_hidden, \n",
        "                                   input_shape = (d_model,),\n",
        "                                   activation = None)\n",
        "        \n",
        "        self.linear_2 = tfkl.Dense(d_model, \n",
        "                                   input_shape = (d_hidden,),\n",
        "                                   activation = None)\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        x = self.linear_1(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.linear_2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Encodr(tfkl.Layer):\n",
        "    def __init__(self,\n",
        "                 d_model: int,\n",
        "                 d_hidden: int,\n",
        "                 q: int,\n",
        "                 v: int,\n",
        "                 h: int,\n",
        "                 mask: bool = False,\n",
        "                 dropout: float = 0.1):\n",
        "        super(Encodr, self).__init__()\n",
        "\n",
        "        self.MHA = MulHeadAtt(d_model=d_model, q=q, v=v, h=h, mask=mask, dropout=dropout)\n",
        "        self.feedforward = FeedFwd(d_model=d_model, d_hidden=d_hidden)\n",
        "        self.dropout = tfkl.Dropout(dropout)\n",
        "        self.layerNormal_1 = tf.keras.layers.LayerNormalization()\n",
        "        self.layerNormal_2 = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        residual = x\n",
        "        x, score = self.MHA(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x + residual\n",
        "        x = self.layerNormal_1(x)\n",
        "\n",
        "        residual = x\n",
        "        x = self.feedforward(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x + residual\n",
        "        x = self.layerNormal_2(x)\n",
        "\n",
        "        return x, score\n",
        "\n",
        "class Transformer(tfkl.Layer):\n",
        "    def __init__(self,\n",
        "                 d_model: int,\n",
        "                 d_output: int,\n",
        "                 d_hidden: int,\n",
        "                 q: int,\n",
        "                 v: int,\n",
        "                 h: int,\n",
        "                 N: int,\n",
        "                 dropout: float = 0.1,\n",
        "                 d_input: int = 36,\n",
        "                 d_channel: int = 6,\n",
        "                 pe: bool = False,\n",
        "                 mask: bool = False):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder_list_1 = [Encodr(d_model=d_model,\n",
        "                               d_hidden=d_hidden,\n",
        "                               q=q,\n",
        "                               v=v,\n",
        "                               h=h,\n",
        "                               mask=mask,\n",
        "                               dropout=dropout) for _ in range(N)]\n",
        "\n",
        "        self.encoder_list_2 = [Encodr(d_model=d_model,\n",
        "                               d_hidden=d_hidden,\n",
        "                               q=q,\n",
        "                               v=v,\n",
        "                               h=h,\n",
        "                               dropout=dropout) for _ in range(N)]\n",
        "\n",
        "        self.embedding_channel = tfkl.Dense(d_model, \n",
        "                                   input_shape = (d_channel,),\n",
        "                                   activation = None)\n",
        "\n",
        "        self.embedding_input = tfkl.Dense(d_model, \n",
        "                                   input_shape = (d_input,),\n",
        "                                   activation = None)\n",
        "\n",
        "        #self.gate = torch.nn.Linear(d_model * d_input + d_model * d_channel, 2)\n",
        "        self.gate = tfkl.Dense(2, \n",
        "                                   input_shape = (d_model * d_input + d_model * d_channel,),\n",
        "                                   activation = None)\n",
        "        #self.output_linear = torch.nn.Linear(d_model * d_input + d_model * d_channel, d_output)\n",
        "        self.output_linear = tfkl.Dense(d_output, \n",
        "                                   input_shape = (d_model * d_input + d_model * d_channel,),\n",
        "                                   activation = None)\n",
        "\n",
        "        self.pe = pe\n",
        "        self._d_input = d_input\n",
        "        self._d_model = d_model\n",
        "\n",
        "    def call(self, x):\n",
        "        \n",
        "        encoding_1 = self.embedding_channel(x)\n",
        "        input_to_gather = encoding_1\n",
        "\n",
        "        if self.pe:\n",
        "            # Create a tensor of ones with the same shape as encoding_1[0]\n",
        "            pe = tf.ones_like(encoding_1[0])\n",
        "\n",
        "            # Create a tensor with values ranging from 0 to self._d_input and add an additional dimension at the end\n",
        "            position = tf.expand_dims(tf.range(self._d_input), axis=-1)\n",
        "\n",
        "            # Create a 1D tensor with values ranging from 0 to self._d_model in steps of 2\n",
        "            temp = tf.range(0, self._d_model, 2)\n",
        "\n",
        "            # Multiply temp by a scalar and exponentiate it\n",
        "            temp = tf.exp(-tf.cast(temp, float32) * tf.cast(math.log(10000) / self._d_model, float32))\n",
        "\n",
        "            # Add a dimension at the beginning of temp\n",
        "            temp = tf.expand_dims(temp, axis=0)\n",
        "\n",
        "            # Multiply position and temp element-wise and flatten the result to a 1D tensor\n",
        "            temp = tf.reshape(tf.cast(position, float32) * tf.cast(temp, float32), [-1])\n",
        "\n",
        "            # Create a tensor of zeros with the same shape as pe\n",
        "            pe_updated = tf.zeros_like(pe)\n",
        "\n",
        "            # Assign the sine of temp to the even-indexed elements of pe_updated\n",
        "            pe_updated = tf.tensor_scatter_nd_update(pe_updated, [[i, j] for i in range(pe.shape[0]) for j in range(0, pe.shape[1], 2)], tf.sin(temp))\n",
        "\n",
        "            # Assign the cosine of temp to the odd-indexed elements of pe_updated\n",
        "            pe_updated = tf.tensor_scatter_nd_update(pe_updated, [[i, j] for i in range(pe.shape[0]) for j in range(1, pe.shape[1], 2)], tf.cos(temp))\n",
        "\n",
        "            # Create a new tensor with the same shape and dtype as pe and copy the values of pe_updated to it\n",
        "            pe = tf.identity(pe_updated)\n",
        "\n",
        "            encoding_1 = encoding_1 + pe\n",
        "\n",
        "        for encoder in self.encoder_list_1:\n",
        "            encoding_1, score_input = encoder(encoding_1)\n",
        "\n",
        "        # channel-wise\n",
        "        encoding_2 = self.embedding_input(tf.transpose(x, perm=[0,2,1]))\n",
        "        channel_to_gather = encoding_2\n",
        "\n",
        "        for encoder in self.encoder_list_2:\n",
        "            encoding_2, score_channel = encoder(encoding_2)\n",
        "\n",
        "        encoding_1 = tf.reshape(encoding_1, [tf.shape(encoding_1)[0], 36*512])\n",
        "        encoding_2 = tf.reshape(encoding_2, [tf.shape(encoding_2)[0], 6*512])\n",
        "\n",
        "        # gate\n",
        "        gate = tf.nn.softmax(self.gate(tf.concat([encoding_1, encoding_2], axis=-1)))\n",
        "        encoding = tf.concat([encoding_1 * gate[:, 0:1], encoding_2 * gate[:, 1:2]], axis=-1)\n",
        "\n",
        "        # output\n",
        "        output = self.output_linear(encoding)\n",
        "\n",
        "        return output#, encoding, score_input, score_channel, input_to_gather, channel_to_gather, gate\n",
        "\n",
        "\n",
        "\n",
        "def build_model(\n",
        "    input_shape\n",
        "):\n",
        "    inputs = tfk.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    output = Transformer(d_model=d_model, d_input=d_input, d_channel=d_channel, d_output=d_output, d_hidden=d_hidden,\n",
        "                      q=q, v=v, h=h, N=N, dropout=dropout, pe=pe, mask=mask)(x)\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "    return tfk.Model(inputs, output)\n",
        "\n",
        "\n",
        "\n",
        "model = build_model(\n",
        "    input_shape\n",
        "    #head_size=256,\n",
        "    #num_heads=4,\n",
        "    #ff_dim=4,\n",
        "    #num_transformer_blocks=4,\n",
        "    #mlp_units=[128],\n",
        "    #mlp_dropout=0.4,\n",
        "    #dropout=0.25,\n",
        ")\n",
        "\n",
        "model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics=\"accuracy\")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0cs2eEI7e46F",
        "outputId": "507e6aea-5c99-44cb-d755-c8e022648325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-874a8195bc0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m model = build_model(\n\u001b[0m\u001b[1;32m    294\u001b[0m     \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;31m#head_size=256,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-874a8195bc0a>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     output = Transformer(d_model=d_model, d_input=d_input, d_channel=d_channel, d_output=d_output, d_hidden=d_hidden,\n\u001b[0m\u001b[1;32m    283\u001b[0m                       q=q, v=v, h=h, N=N, dropout=dropout, pe=pe, mask=mask)(x)\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file75a87d92.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'encoder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mscore_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'score_input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_list_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'encoding_1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'iterate_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'encoder'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0mencoding_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mchannel_to_gather\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file75a87d92.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0;32mnonlocal\u001b[0m \u001b[0mencoding_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                     \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0mencoding_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_input\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                 \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'encoder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mscore_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'score_input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_fileurir1_9p.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMHA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filem1vg8tqh.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0mq_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_or_size_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_chunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mk_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_or_size_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer \"transformer\" (type Transformer).\n\nin user code:\n\n    File \"<ipython-input-5-874a8195bc0a>\", line 254, in call  *\n        encoding_1, score_input = encoder(encoding_1)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_fileurir1_9p.py\", line 11, in tf__call\n        (x, score) = ag__.converted_call(ag__.ld(self).MHA, (ag__.ld(x),), None, fscope)\n    File \"/tmp/__autograph_generated_filem1vg8tqh.py\", line 10, in tf__call\n        q_chunks = ag__.converted_call(ag__.ld(tf).split, (ag__.converted_call(ag__.ld(self).W_q, (ag__.ld(x),), None, fscope),), dict(num_or_size_splits=ag__.ld(self)._h, axis=(- 1)), fscope)\n\n    TypeError: Exception encountered when calling layer \"encodr\" (type Encodr).\n    \n    in user code:\n    \n        File \"<ipython-input-5-874a8195bc0a>\", line 150, in call  *\n            x, score = self.MHA(x)\n        File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/tmp/__autograph_generated_filem1vg8tqh.py\", line 10, in tf__call\n            q_chunks = ag__.converted_call(ag__.ld(tf).split, (ag__.converted_call(ag__.ld(self).W_q, (ag__.ld(x),), None, fscope),), dict(num_or_size_splits=ag__.ld(self)._h, axis=(- 1)), fscope)\n    \n        TypeError: Exception encountered when calling layer \"mul_head_att\" (type MulHeadAtt).\n        \n        in user code:\n        \n            File \"<ipython-input-5-874a8195bc0a>\", line 55, in call  *\n                q_chunks = tf.split(self.W_q(x), num_or_size_splits=self._h, axis=-1)\n        \n            TypeError: 'ResourceVariable' object is not callable\n        \n        \n        Call arguments received by layer \"mul_head_att\" (type MulHeadAtt):\n          • x=tf.Tensor(shape=(None, 36, 512), dtype=float32)\n    \n    \n    Call arguments received by layer \"encodr\" (type Encodr):\n      • x=tf.Tensor(shape=(None, 36, 512), dtype=float32)\n\n\nCall arguments received by layer \"transformer\" (type Transformer):\n  • x=tf.Tensor(shape=(None, 36, 6), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "hgLv_Ga0iZZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    x = X_train,\n",
        "    y = y_train,\n",
        "    batch_size = batch_size,\n",
        "    epochs = 100,\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    #class_weight=class_weights,\n",
        "    callbacks = [\n",
        "        tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=10, restore_best_weights=True),\n",
        "        tfk.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=5, factor=tf.math.exp(-0.1), min_lr=1e-5)\n",
        "    ]\n",
        ").history\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qA4nRIASibE-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}